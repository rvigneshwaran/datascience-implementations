{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with categorical data\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C', 'B'],\n",
    "    'Color': ['Red', 'Green', 'Blue', 'Red', 'Green', 'Red', 'Blue', 'Red', 'Green'],\n",
    "    'Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Medium', 'Small', 'Large'],\n",
    "    'Label': [1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: One-Hot Encoding using pd.get_dummies\n",
    "df_encoded = pd.get_dummies(df, columns=['Category', 'Color', 'Size'], prefix=['Cat', 'Col', 'Size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Label Encoding using pd.factorize\n",
    "df['Size_Label'] = pd.factorize(df['Size'])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Ordinal Encoding using a custom mapping\n",
    "size_mapping = {'Small': 1, 'Medium': 2, 'Large': 3}\n",
    "df['Size_Ordinal'] = df['Size'].map(size_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: category-encoders in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\program files\\python311\\lib\\site-packages (from category-encoders) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (1.11.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\program files\\python311\\lib\\site-packages (from category-encoders) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2022.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.20.0->category-encoders) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels>=0.9.0->category-encoders) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Binary Encoding using category_encoders library\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['Size'])\n",
    "df_binary_encoded = encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Count Encoding using category_encoders\n",
    "encoder = ce.CountEncoder(cols=['Category'])\n",
    "df_count_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Target Encoding using category_encoders\n",
    "encoder = ce.TargetEncoder(cols=['Color'])\n",
    "df_target_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Mean Encoding using groupby and transform\n",
    "mean_encoded = df.groupby('Color')['Label'].transform('mean')\n",
    "df['Color_Mean_Encoded'] = mean_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Frequency Encoding using value_counts\n",
    "freq_encoding = df['Color'].map(df['Color'].value_counts())\n",
    "df['Color_Freq_Encoded'] = freq_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9: Hashing Encoding using category_encoders\n",
    "encoder = ce.HashingEncoder(cols=['Category'], n_components=3)\n",
    "df_hash_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 10: Leave-One-Out Encoding using category_encoders\n",
    "encoder = ce.LeaveOneOutEncoder(cols=['Color'])\n",
    "df_loo_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  \n",
      "0            0.500000                   4  \n",
      "1            0.333333                   3  \n",
      "2            1.000000                   2  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 11: Weight of Evidence Encoding using category_encoders\n",
    "encoder = ce.WOEEncoder(cols=['Category'])\n",
    "df_woe_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 12: James-Stein Encoding using category_encoders\n",
    "encoder = ce.JamesSteinEncoder(cols=['Category'])\n",
    "df_js_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 13: Backward Difference Encoding using category_encoders\n",
    "encoder = ce.BackwardDifferenceEncoder(cols=['Size'])\n",
    "df_bd_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 14: Helmert Encoding using category_encoders\n",
    "encoder = ce.HelmertEncoder(cols=['Size'])\n",
    "df_helmert_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 15: Polynomial Encoding using category_encoders\n",
    "encoder = ce.PolynomialEncoder(cols=['Size'])\n",
    "df_poly_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 16: Bin-counting Encoding using category_encoders\n",
    "encoder = ce.CatBoostEncoder(cols=['Category'])\n",
    "df_cb_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Samples can not be a single string. The input must be an iterable over iterables of strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureHasher\n\u001b[0;32m      3\u001b[0m hasher \u001b[39m=\u001b[39m FeatureHasher(n_features\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, input_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m hashed_features \u001b[39m=\u001b[39m hasher\u001b[39m.\u001b[39;49mtransform(df[\u001b[39m'\u001b[39;49m\u001b[39mSize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m df_hashed_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(hashed_features\u001b[39m.\u001b[39mtoarray(), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSize_hashed_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSize_hashed_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSize_hashed_3\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\_hash.py:169\u001b[0m, in \u001b[0;36mFeatureHasher.transform\u001b[1;34m(self, raw_X)\u001b[0m\n\u001b[0;32m    167\u001b[0m first_raw_X \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(raw_X)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first_raw_X, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    170\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSamples can not be a single string. The input must be an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m over iterables of strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m raw_X_ \u001b[39m=\u001b[39m chain([first_raw_X], raw_X)\n\u001b[0;32m    174\u001b[0m raw_X \u001b[39m=\u001b[39m (((f, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m raw_X_)\n",
      "\u001b[1;31mValueError\u001b[0m: Samples can not be a single string. The input must be an iterable over iterables of strings."
     ]
    }
   ],
   "source": [
    "# Example 17: Feature Hashing using sklearn's FeatureHasher\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "hasher = FeatureHasher(n_features=3, input_type='string')\n",
    "hashed_features = hasher.transform(df['Size'])\n",
    "df_hashed_features = pd.DataFrame(hashed_features.toarray(), columns=['Size_hashed_1', 'Size_hashed_2', 'Size_hashed_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 18: Encoding with Frequency and Mean for high cardinality categories\n",
    "category_counts = df['Category'].value_counts()\n",
    "category_means = df.groupby('Category')['Label'].mean()\n",
    "df['Category_Freq_Encoded'] = df['Category'].map(category_counts)\n",
    "df['Category_Mean_Encoded'] = df['Category'].map(category_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 19: Encoding with Frequency and Mean for Color and Size\n",
    "color_counts = df['Color'].value_counts()\n",
    "color_means = df.groupby('Color')['Label'].mean()\n",
    "size_counts = df['Size'].value_counts()\n",
    "size_means = df.groupby('Size')['Label'].mean()\n",
    "df['Color_Freq_Encoded'] = df['Color'].map(color_counts)\n",
    "df['Color_Mean_Encoded'] = df['Color'].map(color_means)\n",
    "df['Size_Freq_Encoded'] = df['Size'].map(size_counts)\n",
    "df['Size_Mean_Encoded'] = df['Size'].map(size_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 20: Encoding with Frequency and Mean for Size_Label\n",
    "size_label_counts = df['Size_Label'].value_counts()\n",
    "size_label_means = df.groupby('Size_Label')['Label'].mean()\n",
    "df['Size_Label_Freq_Encoded'] = df['Size_Label'].map(size_label_counts)\n",
    "df['Size_Label_Mean_Encoded'] = df['Size_Label'].map(size_label_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  Size_Freq_Encoded  Size_Mean_Encoded  \\\n",
      "0               0.666667                  3           0.666667   \n",
      "1               0.333333                  3           0.666667   \n",
      "2               0.666667                  3           0.333333   \n",
      "\n",
      "   Size_Label_Freq_Encoded  Size_Label_Mean_Encoded  \n",
      "0                        3                 0.666667  \n",
      "1                        3                 0.666667  \n",
      "2                        3                 0.333333  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
