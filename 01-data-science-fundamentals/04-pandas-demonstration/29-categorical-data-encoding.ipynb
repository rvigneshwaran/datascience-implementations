{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with categorical data\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C', 'B'],\n",
    "    'Color': ['Red', 'Green', 'Blue', 'Red', 'Green', 'Red', 'Blue', 'Red', 'Green'],\n",
    "    'Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Medium', 'Small', 'Large'],\n",
    "    'Label': [1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: One-Hot Encoding using pd.get_dummies\n",
    "df_encoded = pd.get_dummies(df, columns=['Category', 'Color', 'Size'], prefix=['Cat', 'Col', 'Size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Label Encoding using pd.factorize\n",
    "df['Size_Label'] = pd.factorize(df['Size'])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Ordinal Encoding using a custom mapping\n",
    "size_mapping = {'Small': 1, 'Medium': 2, 'Large': 3}\n",
    "df['Size_Ordinal'] = df['Size'].map(size_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: category-encoders in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\program files\\python311\\lib\\site-packages (from category-encoders) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (1.11.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\program files\\python311\\lib\\site-packages (from category-encoders) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from category-encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2022.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.20.0->category-encoders) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rvign\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels>=0.9.0->category-encoders) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Binary Encoding using category_encoders library\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['Size'])\n",
    "df_binary_encoded = encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Count Encoding using category_encoders\n",
    "encoder = ce.CountEncoder(cols=['Category'])\n",
    "df_count_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Target Encoding using category_encoders\n",
    "encoder = ce.TargetEncoder(cols=['Color'])\n",
    "df_target_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Mean Encoding using groupby and transform\n",
    "mean_encoded = df.groupby('Color')['Label'].transform('mean')\n",
    "df['Color_Mean_Encoded'] = mean_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Frequency Encoding using value_counts\n",
    "freq_encoding = df['Color'].map(df['Color'].value_counts())\n",
    "df['Color_Freq_Encoded'] = freq_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9: Hashing Encoding using category_encoders\n",
    "encoder = ce.HashingEncoder(cols=['Category'], n_components=3)\n",
    "df_hash_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 10: Leave-One-Out Encoding using category_encoders\n",
    "encoder = ce.LeaveOneOutEncoder(cols=['Color'])\n",
    "df_loo_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  \n",
      "0            0.500000                   4  \n",
      "1            0.333333                   3  \n",
      "2            1.000000                   2  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 11: Weight of Evidence Encoding using category_encoders\n",
    "encoder = ce.WOEEncoder(cols=['Category'])\n",
    "df_woe_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 12: James-Stein Encoding using category_encoders\n",
    "encoder = ce.JamesSteinEncoder(cols=['Category'])\n",
    "df_js_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 13: Backward Difference Encoding using category_encoders\n",
    "encoder = ce.BackwardDifferenceEncoder(cols=['Size'])\n",
    "df_bd_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 14: Helmert Encoding using category_encoders\n",
    "encoder = ce.HelmertEncoder(cols=['Size'])\n",
    "df_helmert_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\rvign\\AppData\\Roaming\\Python\\Python311\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "# Example 15: Polynomial Encoding using category_encoders\n",
    "encoder = ce.PolynomialEncoder(cols=['Size'])\n",
    "df_poly_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 16: Bin-counting Encoding using category_encoders\n",
    "encoder = ce.CatBoostEncoder(cols=['Category'])\n",
    "df_cb_encoded = encoder.fit_transform(df, df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Samples can not be a single string. The input must be an iterable over iterables of strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureHasher\n\u001b[0;32m      3\u001b[0m hasher \u001b[39m=\u001b[39m FeatureHasher(n_features\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, input_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m hashed_features \u001b[39m=\u001b[39m hasher\u001b[39m.\u001b[39;49mtransform(df[\u001b[39m'\u001b[39;49m\u001b[39mSize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m df_hashed_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(hashed_features\u001b[39m.\u001b[39mtoarray(), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSize_hashed_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSize_hashed_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSize_hashed_3\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\_hash.py:169\u001b[0m, in \u001b[0;36mFeatureHasher.transform\u001b[1;34m(self, raw_X)\u001b[0m\n\u001b[0;32m    167\u001b[0m first_raw_X \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(raw_X)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first_raw_X, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    170\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSamples can not be a single string. The input must be an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m over iterables of strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m raw_X_ \u001b[39m=\u001b[39m chain([first_raw_X], raw_X)\n\u001b[0;32m    174\u001b[0m raw_X \u001b[39m=\u001b[39m (((f, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m raw_X_)\n",
      "\u001b[1;31mValueError\u001b[0m: Samples can not be a single string. The input must be an iterable over iterables of strings."
     ]
    }
   ],
   "source": [
    "# Example 17: Feature Hashing using sklearn's FeatureHasher\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "hasher = FeatureHasher(n_features=3, input_type='string')\n",
    "hashed_features = hasher.transform(df['Size'])\n",
    "df_hashed_features = pd.DataFrame(hashed_features.toarray(), columns=['Size_hashed_1', 'Size_hashed_2', 'Size_hashed_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 18: Encoding with Frequency and Mean for high cardinality categories\n",
    "category_counts = df['Category'].value_counts()\n",
    "category_means = df.groupby('Category')['Label'].mean()\n",
    "df['Category_Freq_Encoded'] = df['Category'].map(category_counts)\n",
    "df['Category_Mean_Encoded'] = df['Category'].map(category_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 19: Encoding with Frequency and Mean for Color and Size\n",
    "color_counts = df['Color'].value_counts()\n",
    "color_means = df.groupby('Color')['Label'].mean()\n",
    "size_counts = df['Size'].value_counts()\n",
    "size_means = df.groupby('Size')['Label'].mean()\n",
    "df['Color_Freq_Encoded'] = df['Color'].map(color_counts)\n",
    "df['Color_Mean_Encoded'] = df['Color'].map(color_means)\n",
    "df['Size_Freq_Encoded'] = df['Size'].map(size_counts)\n",
    "df['Size_Mean_Encoded'] = df['Size'].map(size_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 20: Encoding with Frequency and Mean for Size_Label\n",
    "size_label_counts = df['Size_Label'].value_counts()\n",
    "size_label_means = df.groupby('Size_Label')['Label'].mean()\n",
    "df['Size_Label_Freq_Encoded'] = df['Size_Label'].map(size_label_counts)\n",
    "df['Size_Label_Mean_Encoded'] = df['Size_Label'].map(size_label_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  Size_Freq_Encoded  Size_Mean_Encoded  \\\n",
      "0               0.666667                  3           0.666667   \n",
      "1               0.333333                  3           0.666667   \n",
      "2               0.666667                  3           0.333333   \n",
      "\n",
      "   Size_Label_Freq_Encoded  Size_Label_Mean_Encoded  \n",
      "0                        3                 0.666667  \n",
      "1                        3                 0.666667  \n",
      "2                        3                 0.333333  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 21: Grouping and Encoding with Grouped Mean\n",
    "grouped_means = df.groupby('Category')['Label'].transform('mean')\n",
    "df['Category_Grouped_Mean_Encoded'] = grouped_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 22: Frequency Encoding with Noise\n",
    "noise = 0.1\n",
    "import numpy as np\n",
    "df['Color_Freq_Noise_Encoded'] = df['Color_Freq_Encoded'] + noise * np.random.randn(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 23: Handling Unknown Categories with Target Mean Encoding\n",
    "unknown_category = 'D'\n",
    "df_unknown_category = df.copy()\n",
    "df_unknown_category.loc[6, 'Category'] = unknown_category\n",
    "df_unknown_category['Category_Unknown_Mean_Encoded'] = df_unknown_category.groupby('Category')['Label'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 24: Handling Rare Categories with Frequency Encoding\n",
    "threshold = 2\n",
    "rare_categories = df['Size'].value_counts()[df['Size'].value_counts() < threshold].index\n",
    "df['Size_Rare_Encoded'] = df['Size'].apply(lambda x: 'Rare' if x in rare_categories else x)\n",
    "df['Size_Rare_Freq_Encoded'] = df['Size_Rare_Encoded'].map(df['Size_Rare_Encoded'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 25: Mean Encoding with Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "df['Category_CV_Mean_Encoded'] = 0\n",
    "for train_idx, val_idx in kf.split(df):\n",
    "    mean_map = df.iloc[train_idx].groupby('Category')['Label'].mean()\n",
    "    df.loc[val_idx, 'Category_CV_Mean_Encoded'] = df.loc[val_idx, 'Category'].map(mean_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 26: Weight of Evidence Encoding with Cross-Validation\n",
    "encoder = ce.WOEEncoder(cols=['Size_Label'])\n",
    "df['Size_Label_CV_WOE_Encoded'] = 0\n",
    "for train_idx, val_idx in kf.split(df):\n",
    "    encoder.fit(df.iloc[train_idx], df.iloc[train_idx]['Label'])\n",
    "    df.loc[val_idx, 'Size_Label_CV_WOE_Encoded'] = encoder.transform(df.iloc[val_idx])['Size_Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 27: Handling Categorical Missing Data with Encoding\n",
    "df_missing = df.copy()\n",
    "df_missing.loc[1, 'Color'] = None\n",
    "df_missing.loc[3, 'Color'] = None\n",
    "df_missing['Color_Missing_Encoded'] = df_missing['Color'].fillna('Missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Size_Missing_Encoded'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Size_Missing_Encoded'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Example 28: Custom Encoding for Ordinal Categories\u001b[39;00m\n\u001b[0;32m      2\u001b[0m ordinal_mapping \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mSmall\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMedium\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLarge\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m df_missing[\u001b[39m'\u001b[39m\u001b[39mSize_Ordinal_Custom_Encoded\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_missing[\u001b[39m'\u001b[39;49m\u001b[39mSize_Missing_Encoded\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmap(ordinal_mapping)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Size_Missing_Encoded'"
     ]
    }
   ],
   "source": [
    "# Example 28: Custom Encoding for Ordinal Categories\n",
    "ordinal_mapping = {'Small': 1, 'Medium': 2, 'Large': 3, 'Missing': 0}\n",
    "df_missing['Size_Ordinal_Custom_Encoded'] = df_missing['Size_Missing_Encoded'].map(ordinal_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 29: Count Encoding with Smoothing\n",
    "smoothing = 2\n",
    "df['Color_Count_Smooth_Encoded'] = (df['Color'].map(df['Color'].value_counts()) + smoothing) / (df['Color'].value_counts().sum() + smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 30: Combining Multiple Encodings\n",
    "df_combined = df.copy()\n",
    "df_combined['Category_Freq_Size_Label_Mean_Encoded'] = df_combined['Category_Freq_Encoded'] * df_combined['Size_Label_Mean_Encoded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  ...  Size_Mean_Encoded  Size_Label_Freq_Encoded  \\\n",
      "0               0.666667  ...           0.666667                        3   \n",
      "1               0.333333  ...           0.666667                        3   \n",
      "2               0.666667  ...           0.333333                        3   \n",
      "\n",
      "   Size_Label_Mean_Encoded  Category_Grouped_Mean_Encoded  \\\n",
      "0                 0.666667                       0.666667   \n",
      "1                 0.666667                       0.333333   \n",
      "2                 0.333333                       0.666667   \n",
      "\n",
      "   Color_Freq_Noise_Encoded  Size_Rare_Encoded Size_Rare_Freq_Encoded  \\\n",
      "0                  3.871235              Small                      3   \n",
      "1                  2.953926             Medium                      3   \n",
      "2                  2.058294              Large                      3   \n",
      "\n",
      "   Category_CV_Mean_Encoded  Size_Label_CV_WOE_Encoded  \\\n",
      "0                       1.0                  -0.182322   \n",
      "1                       0.5                   0.916291   \n",
      "2                       0.5                   0.000000   \n",
      "\n",
      "   Color_Count_Smooth_Encoded  \n",
      "0                    0.545455  \n",
      "1                    0.454545  \n",
      "2                    0.363636  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 31: Frequency Encoding with Cross-Validation\n",
    "df['Size_CV_Freq_Encoded'] = 0\n",
    "for train_idx, val_idx in kf.split(df):\n",
    "    freq_map = df.iloc[train_idx]['Size'].value_counts()\n",
    "    df.loc[val_idx, 'Size_CV_Freq_Encoded'] = df.loc[val_idx, 'Size'].map(freq_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 32: Mean Encoding with Feature Interaction\n",
    "df['Category_Size_Label_Mean_Encoded'] = df.groupby(['Category', 'Size_Label'])['Label'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 33: Label Encoding with Order\n",
    "order_mapping = {'Small': 1, 'Medium': 2, 'Large': 3}\n",
    "df['Size_Label_Order_Encoded'] = df['Size_Label'].map(order_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 34: Encoding with Lag Features\n",
    "df_lag_encoded = df.copy()\n",
    "df_lag_encoded['Label_Lag1'] = df_lag_encoded.groupby('Category')['Label'].shift(1)\n",
    "df_lag_encoded['Label_Lag2'] = df_lag_encoded.groupby('Category')['Label'].shift(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 35: Encoding with Rolling Mean\n",
    "df_rolling_encoded = df.copy()\n",
    "df_rolling_encoded['Rolling_Mean'] = df_rolling_encoded.groupby('Category')['Label'].rolling(window=2, min_periods=1).mean().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 36: Encoding with Expanding Mean\n",
    "df_expanding_encoded = df.copy()\n",
    "df_expanding_encoded['Expanding_Mean'] = df_expanding_encoded.groupby('Category')['Label'].expanding(min_periods=1).mean().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 37: Encoding with Moving Average\n",
    "df_moving_avg_encoded = df.copy()\n",
    "df_moving_avg_encoded['Moving_Avg'] = df_moving_avg_encoded.groupby('Category')['Label'].rolling(window=2, min_periods=1).mean().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 38: Encoding with Exponential Moving Average\n",
    "span = 2\n",
    "alpha = 2 / (span + 1)\n",
    "df_ema_encoded = df.copy()\n",
    "df_ema_encoded['EMA'] = df_ema_encoded.groupby('Category')['Label'].ewm(span=span, adjust=False).mean().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 39: Encoding with Shifted Rolling Mean\n",
    "df_shifted_encoded = df.copy()\n",
    "df_shifted_encoded['Shifted_Rolling_Mean'] = df_shifted_encoded.groupby('Category')['Label'].rolling(window=2, min_periods=1).mean().shift(1).reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 40: Encoding with Expanding Max\n",
    "df_expanding_max_encoded = df.copy()\n",
    "df_expanding_max_encoded['Expanding_Max'] = df_expanding_max_encoded.groupby('Category')['Label'].expanding(min_periods=1).max().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  ...  Category_Grouped_Mean_Encoded  \\\n",
      "0               0.666667  ...                       0.666667   \n",
      "1               0.333333  ...                       0.333333   \n",
      "2               0.666667  ...                       0.666667   \n",
      "\n",
      "   Color_Freq_Noise_Encoded  Size_Rare_Encoded  Size_Rare_Freq_Encoded  \\\n",
      "0                  3.871235              Small                       3   \n",
      "1                  2.953926             Medium                       3   \n",
      "2                  2.058294              Large                       3   \n",
      "\n",
      "   Category_CV_Mean_Encoded  Size_Label_CV_WOE_Encoded  \\\n",
      "0                       1.0                  -0.182322   \n",
      "1                       0.5                   0.916291   \n",
      "2                       0.5                   0.000000   \n",
      "\n",
      "  Color_Count_Smooth_Encoded  Size_CV_Freq_Encoded  \\\n",
      "0                   0.545455                     2   \n",
      "1                   0.454545                     2   \n",
      "2                   0.363636                     1   \n",
      "\n",
      "   Category_Size_Label_Mean_Encoded  Size_Label_Order_Encoded  \n",
      "0                               1.0                       NaN  \n",
      "1                               0.5                       NaN  \n",
      "2                               0.5                       NaN  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 41: Encoding with Shifted Expanding Max\n",
    "df_shifted_expanding_max_encoded = df.copy()\n",
    "df_shifted_expanding_max_encoded['Shifted_Expanding_Max'] = df_shifted_expanding_max_encoded.groupby('Category')['Label'].expanding(min_periods=1).max().shift(1).reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 42: Encoding with Cumulative Count\n",
    "df_cumulative_count_encoded = df.copy()\n",
    "df_cumulative_count_encoded['Cumulative_Count'] = df_cumulative_count_encoded.groupby('Category').cumcount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 43: Encoding with Rank\n",
    "df_rank_encoded = df.copy()\n",
    "df_rank_encoded['Rank'] = df_rank_encoded.groupby('Category')['Label'].rank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 44: Encoding with Group Mean and Size\n",
    "df_group_encoded = df.copy()\n",
    "df_group_encoded['Category_Size_Label_Group_Mean'] = df_group_encoded.groupby(['Category', 'Size_Label'])['Label'].transform('mean')\n",
    "df_group_encoded['Category_Size_Group_Size'] = df_group_encoded.groupby(['Category', 'Size'])['Label'].transform('size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 45: Encoding with Group Cumulative Count\n",
    "df_group_cumulative_count_encoded = df.copy()\n",
    "df_group_cumulative_count_encoded['Category_Group_Cumulative_Count'] = df_group_cumulative_count_encoded.groupby('Category').cumcount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 46: Encoding with Group Rank\n",
    "df_group_rank_encoded = df.copy()\n",
    "df_group_rank_encoded['Category_Group_Rank'] = df_group_rank_encoded.groupby('Category')['Label'].rank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 47: Encoding with Group Expanding Max\n",
    "df_group_expanding_max_encoded = df.copy()\n",
    "df_group_expanding_max_encoded['Category_Group_Expanding_Max'] = df_group_expanding_max_encoded.groupby('Category')['Label'].expanding(min_periods=1).max().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 48: Encoding with Group Shifted Expanding Max\n",
    "df_group_shifted_expanding_max_encoded = df.copy()\n",
    "df_group_shifted_expanding_max_encoded['Category_Group_Shifted_Expanding_Max'] = df_group_shifted_expanding_max_encoded.groupby('Category')['Label'].expanding(min_periods=1).max().shift(1).reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 49: Encoding with Group Cumulative Sum\n",
    "df_group_cumulative_sum_encoded = df.copy()\n",
    "df_group_cumulative_sum_encoded['Category_Group_Cumulative_Sum'] = df_group_cumulative_sum_encoded.groupby('Category')['Label'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 50: Encoding with Group Z-Score\n",
    "df_group_zscore_encoded = df.copy()\n",
    "df_group_zscore_encoded['Category_Group_Z_Score'] = (df_group_zscore_encoded['Label'] - df_group_zscore_encoded.groupby('Category')['Label'].transform('mean')) / df_group_zscore_encoded.groupby('Category')['Label'].transform('std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  ...  Category_Grouped_Mean_Encoded  \\\n",
      "0               0.666667  ...                       0.666667   \n",
      "1               0.333333  ...                       0.333333   \n",
      "2               0.666667  ...                       0.666667   \n",
      "\n",
      "   Color_Freq_Noise_Encoded  Size_Rare_Encoded  Size_Rare_Freq_Encoded  \\\n",
      "0                  3.871235              Small                       3   \n",
      "1                  2.953926             Medium                       3   \n",
      "2                  2.058294              Large                       3   \n",
      "\n",
      "   Category_CV_Mean_Encoded  Size_Label_CV_WOE_Encoded  \\\n",
      "0                       1.0                  -0.182322   \n",
      "1                       0.5                   0.916291   \n",
      "2                       0.5                   0.000000   \n",
      "\n",
      "  Color_Count_Smooth_Encoded  Size_CV_Freq_Encoded  \\\n",
      "0                   0.545455                     2   \n",
      "1                   0.454545                     2   \n",
      "2                   0.363636                     1   \n",
      "\n",
      "   Category_Size_Label_Mean_Encoded  Size_Label_Order_Encoded  \n",
      "0                               1.0                       NaN  \n",
      "1                               0.5                       NaN  \n",
      "2                               0.5                       NaN  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 51: Encoding with Group Shifted Cumulative Sum\n",
    "df_group_shifted_cumulative_sum_encoded = df.copy()\n",
    "df_group_shifted_cumulative_sum_encoded['Category_Group_Shifted_Cumulative_Sum'] = df_group_shifted_cumulative_sum_encoded.groupby('Category')['Label'].cumsum().shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 52: Encoding with Group Min-Max Scaling\n",
    "df_group_minmax_encoded = df.copy()\n",
    "df_group_minmax_encoded['Category_Group_MinMax'] = (df_group_minmax_encoded['Label'] - df_group_minmax_encoded.groupby('Category')['Label'].transform('min')) / (df_group_minmax_encoded.groupby('Category')['Label'].transform('max') - df_group_minmax_encoded.groupby('Category')['Label'].transform('min'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 53: Encoding with Group Standardization\n",
    "df_group_standardized_encoded = df.copy()\n",
    "df_group_standardized_encoded['Category_Group_Standardized'] = (df_group_standardized_encoded['Label'] - df_group_standardized_encoded.groupby('Category')['Label'].transform('mean')) / df_group_standardized_encoded.groupby('Category')['Label'].transform('std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 54: Encoding with Group Robust Scaling\n",
    "df_group_robust_encoded = df.copy()\n",
    "df_group_robust_encoded['Category_Group_Robust'] = (df_group_robust_encoded['Label'] - df_group_robust_encoded.groupby('Category')['Label'].transform('median')) / (df_group_robust_encoded.groupby('Category')['Label'].transform('quantile', 0.75) - df_group_robust_encoded.groupby('Category')['Label'].transform('quantile', 0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 55: Encoding with Group Min-Max Scaling and Shifted Mean\n",
    "df_group_minmax_shifted_encoded = df.copy()\n",
    "df_group_minmax_shifted_encoded['Category_Group_MinMax_Shifted'] = (df_group_minmax_shifted_encoded['Label'] - df_group_minmax_shifted_encoded.groupby('Category')['Label'].transform('min')) / (df_group_minmax_shifted_encoded.groupby('Category')['Label'].transform('max') - df_group_minmax_shifted_encoded.groupby('Category')['Label'].transform('min')) + df_group_minmax_shifted_encoded.groupby('Category')['Label'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 56: Encoding with Group Z-Score and Shifted Median\n",
    "df_group_zscore_shifted_encoded = df.copy()\n",
    "df_group_zscore_shifted_encoded['Category_Group_Z_Score_Shifted'] = (df_group_zscore_shifted_encoded['Label'] - df_group_zscore_shifted_encoded.groupby('Category')['Label'].transform('mean')) / df_group_zscore_shifted_encoded.groupby('Category')['Label'].transform('std') + df_group_zscore_shifted_encoded.groupby('Category')['Label'].transform('median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 57: Encoding with Group Rank and Normalization\n",
    "df_group_rank_normalized_encoded = df.copy()\n",
    "df_group_rank_normalized_encoded['Category_Group_Rank_Normalized'] = (df_group_rank_normalized_encoded.groupby('Category')['Label'].rank() - 1) / (df_group_rank_normalized_encoded.groupby('Category')['Label'].transform('size') - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 58: Encoding with Group Min-Max Scaling and Group Mean\n",
    "df_group_minmax_group_mean_encoded = df.copy()\n",
    "df_group_minmax_group_mean_encoded['Category_Group_MinMax_Group_Mean'] = (df_group_minmax_group_mean_encoded['Label'] - df_group_minmax_group_mean_encoded.groupby('Category')['Label'].transform('min')) / (df_group_minmax_group_mean_encoded.groupby('Category')['Label'].transform('max') - df_group_minmax_group_mean_encoded.groupby('Category')['Label'].transform('min')) * df_group_minmax_group_mean_encoded.groupby('Category')['Label'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 59: Encoding with Group Z-Score and Group Mean\n",
    "df_group_zscore_group_mean_encoded = df.copy()\n",
    "df_group_zscore_group_mean_encoded['Category_Group_Z_Score_Group_Mean'] = (df_group_zscore_group_mean_encoded['Label'] - df_group_zscore_group_mean_encoded.groupby('Category')['Label'].transform('mean')) / df_group_zscore_group_mean_encoded.groupby('Category')['Label'].transform('std') * df_group_zscore_group_mean_encoded.groupby('Category')['Label'].transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 60: Encoding with Group Rank and Group Standard Deviation\n",
    "df_group_rank_group_std_encoded = df.copy()\n",
    "df_group_rank_group_std_encoded['Category_Group_Rank_Group_Std'] = df_group_rank_group_std_encoded.groupby('Category')['Label'].rank() / df_group_rank_group_std_encoded.groupby('Category')['Label'].transform('std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Color    Size  Label  Size_Label  Size_Ordinal  \\\n",
      "0        A    Red   Small      1           0             1   \n",
      "1        B  Green  Medium      0           1             2   \n",
      "2        A   Blue   Large      1           2             3   \n",
      "\n",
      "   Color_Mean_Encoded  Color_Freq_Encoded  Category_Freq_Encoded  \\\n",
      "0            0.500000                   4                      3   \n",
      "1            0.333333                   3                      3   \n",
      "2            1.000000                   2                      3   \n",
      "\n",
      "   Category_Mean_Encoded  ...  Category_Grouped_Mean_Encoded  \\\n",
      "0               0.666667  ...                       0.666667   \n",
      "1               0.333333  ...                       0.333333   \n",
      "2               0.666667  ...                       0.666667   \n",
      "\n",
      "   Color_Freq_Noise_Encoded  Size_Rare_Encoded  Size_Rare_Freq_Encoded  \\\n",
      "0                  3.871235              Small                       3   \n",
      "1                  2.953926             Medium                       3   \n",
      "2                  2.058294              Large                       3   \n",
      "\n",
      "   Category_CV_Mean_Encoded  Size_Label_CV_WOE_Encoded  \\\n",
      "0                       1.0                  -0.182322   \n",
      "1                       0.5                   0.916291   \n",
      "2                       0.5                   0.000000   \n",
      "\n",
      "  Color_Count_Smooth_Encoded  Size_CV_Freq_Encoded  \\\n",
      "0                   0.545455                     2   \n",
      "1                   0.454545                     2   \n",
      "2                   0.363636                     1   \n",
      "\n",
      "   Category_Size_Label_Mean_Encoded  Size_Label_Order_Encoded  \n",
      "0                               1.0                       NaN  \n",
      "1                               0.5                       NaN  \n",
      "2                               0.5                       NaN  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 61: Encoding with Group Min-Max Scaling and Group Median\n",
    "df_group_minmax_group_median_encoded = df.copy()\n",
    "df_group_minmax_group_median_encoded['Category_Group_MinMax_Group_Median'] = (df_group_minmax_group_median_encoded['Label'] - df_group_minmax_group_median_encoded.groupby('Category')['Label'].transform('min')) / (df_group_minmax_group_median_encoded.groupby('Category')['Label'].transform('max') - df_group_minmax_group_median_encoded.groupby('Category')['Label'].transform('min')) * df_group_minmax_group_median_encoded.groupby('Category')['Label'].transform('median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 62: Encoding with Group Z-Score and Group Median\n",
    "df_group_zscore_group_median_encoded = df.copy()\n",
    "df_group_zscore_group_median_encoded['Category_Group_Z_Score_Group_Median'] = (df_group_zscore_group_median_encoded['Label'] - df_group_zscore_group_median_encoded.groupby('Category')['Label'].transform('mean')) / df_group_zscore_group_median_encoded.groupby('Category')['Label'].transform('std') * df_group_zscore_group_median_encoded.groupby('Category')['Label'].transform('median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 63: Encoding with Group Rank and Group Min-Max Scaling\n",
    "df_group_rank_group_minmax_encoded = df.copy()\n",
    "df_group_rank_group_minmax_encoded['Category_Group_Rank_Group_MinMax'] = df_group_rank_group_minmax_encoded.groupby('Category')['Label'].rank() / (df_group_rank_group_minmax_encoded.groupby('Category')['Label'].transform('size') - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 64: Encoding with Group Rank and Group Max\n",
    "df_group_rank_group_max_encoded = df.copy()\n",
    "df_group_rank_group_max_encoded['Category_Group_Rank_Group_Max'] = df_group_rank_group_max_encoded.groupby('Category')['Label'].rank() / df_group_rank_group_max_encoded.groupby('Category')['Label'].transform('max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 65: Encoding with Group Rank and Group Mean-Median Difference\n",
    "df_group_rank_group_mean_median_diff_encoded = df.copy()\n",
    "df_group_rank_group_mean_median_diff_encoded['Category_Group_Rank_Group_Mean_Median_Diff'] = df_group_rank_group_mean_median_diff_encoded.groupby('Category')['Label'].rank() - df_group_rank_group_mean_median_diff_encoded.groupby('Category')['Label'].transform('median')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
